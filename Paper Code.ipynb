{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":12573204,"sourceType":"datasetVersion","datasetId":7940296}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\n# --- A Better Way to Verify Paths ---\n\nfile_count = 0\nprint(\"--- Verifying file paths (showing first 20 as an example) ---\")\n\n# The path has been corrected to one level up\nfor dirname, _, filenames in os.walk('/kaggle/input/multimodel-emotion-data/'):\n    for filename in filenames:\n        # The condition is now correctly set to '< 20'\n        if file_count < 20:\n            print(os.path.join(dirname, filename))\n        file_count += 1\n\nprint(\"\\n...\")\nprint(f\"âœ… Verification complete. Total files found: {file_count}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:13:18.853079Z","iopub.execute_input":"2025-08-09T04:13:18.853290Z","iopub.status.idle":"2025-08-09T04:14:20.104895Z","shell.execute_reply.started":"2025-08-09T04:13:18.853272Z","shell.execute_reply":"2025-08-09T04:14:20.104265Z"}},"outputs":[{"name":"stdout","text":"--- Verifying file paths (showing first 20 as an example) ---\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/speech_features.pkl\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/Paper.ipynb\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/Research Paper.ipynb\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/The DEAP.txt\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/EDA_DEAP.ipynb\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s20.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s17.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s31.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s14.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s32.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s28.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s24.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s18.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s22.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s02.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s26.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s29.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s25.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s09.dat\n/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/DEAP (EEG)/deap-dataset/data_preprocessed_python/s06.dat\n\n...\nâœ… Verification complete. Total files found: 84251\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install pennylane","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:20.105598Z","iopub.execute_input":"2025-08-09T04:14:20.105776Z","iopub.status.idle":"2025-08-09T04:14:30.446507Z","shell.execute_reply.started":"2025-08-09T04:14:20.105761Z","shell.execute_reply":"2025-08-09T04:14:30.445621Z"}},"outputs":[{"name":"stdout","text":"Collecting pennylane\n  Downloading pennylane-0.42.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.5)\nCollecting rustworkx>=0.14.0 (from pennylane)\n  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.8.0)\nCollecting appdirs (from pennylane)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nCollecting autoray>=0.6.11 (from pennylane)\n  Downloading autoray-0.7.2-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\nCollecting pennylane-lightning>=0.42 (from pennylane)\n  Downloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.4)\nRequirement already satisfied: tomlkit in /usr/local/lib/python3.11/dist-packages (from pennylane) (0.13.3)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.14.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (25.0)\nCollecting diastatic-malt (from pennylane)\n  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\nCollecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.42->pennylane)\n  Downloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2.4.1)\nRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.1.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.6.15)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nRequirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pennylane) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pennylane) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pennylane) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pennylane) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pennylane) (2024.2.0)\nDownloading pennylane-0.42.1-py3-none-any.whl (4.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading autoray-0.7.2-py3-none-any.whl (930 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pennylane_lightning-0.42.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy_openblas32-0.3.30.0.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, autoray, diastatic-malt, rustworkx, pennylane-lightning, pennylane\nSuccessfully installed appdirs-1.4.4 autoray-0.7.2 diastatic-malt-2.15.2 pennylane-0.42.1 pennylane-lightning-0.42.0 rustworkx-0.16.0 scipy-openblas32-0.3.30.0.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ==============================================================================\n#                      MAIN RESEARCH SCRIPT\n#  Quantum Cognitive Computing for Multimodal Emotion Recognition\n# ==============================================================================\n\n# --------------------------------------------------------------------------\n## 1. SETUP AND IMPORTS\n# --------------------------------------------------------------------------\nimport os\nimport pickle\nimport warnings\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport pennylane as qml\nfrom pennylane import numpy as np\n\nimport pandas as pd\nimport librosa\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom transformers import BertModel, BertTokenizer\n\n# --- Configuration ---\nwarnings.filterwarnings(\"ignore\")\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {DEVICE}\")\n\n\n# Set base path to the current folder, since the notebook is inside Datasets\n# Use this corrected path in your main script\nBASE_PATH = '/kaggle/input/multimodel-emotion-data/multimodal-emotion-data/'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:30.448386Z","iopub.execute_input":"2025-08-09T04:14:30.448617Z","iopub.status.idle":"2025-08-09T04:14:59.147740Z","shell.execute_reply.started":"2025-08-09T04:14:30.448595Z","shell.execute_reply":"2025-08-09T04:14:59.146923Z"}},"outputs":[{"name":"stderr","text":"2025-08-09 04:14:49.502419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754712889.722299      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754712889.785830      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\n# --------------------------------------------------------------------------\n## 2. DATA LOADING & PREPROCESSING FUNCTIONS\n#\n# These functions are tailored to your specific folder structures.\n# --------------------------------------------------------------------------\n\ndef load_text_data(path=os.path.join(BASE_PATH, 'Emotion Detection using TEXT/emotion_dataset_raw.csv')):\n    \"\"\"Loads and preprocesses the text data from your CSV file.\"\"\"\n    print(\"Loading text data...\")\n    df = pd.read_csv(path)\n    # The CSV has 'Emotion' and 'Text' columns, which is perfect.\n    texts = df['Text'].tolist()\n    labels = df['Emotion'].tolist()\n    \n    # Encode labels to integers\n    label_encoder = LabelEncoder()\n    labels_encoded = label_encoder.fit_transform(labels)\n    \n    # Tokenize text\n    tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n    inputs = tokenizer(texts, padding='max_length', truncation=True, max_length=64, return_tensors=\"pt\")\n    \n    print(f\"Text data loaded. Found {len(texts)} samples.\")\n    return inputs['input_ids'], inputs['attention_mask'], torch.tensor(labels_encoded, dtype=torch.long), label_encoder\n\ndef load_image_data(path='/kaggle/input/fer2013/'): # Updated path\n    \"\"\"\n    Loads the image data from the complete FER-2013 dataset.\n    \"\"\"\n    print(\"Loading image data from FER-2013 dataset...\")\n    \n    # Define transformations. FER-2013 images are grayscale, so we convert to RGB.\n    transform = transforms.Compose([\n        transforms.Grayscale(num_output_channels=3), # Convert grayscale to 3-channel RGB\n        transforms.Resize((64, 64)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n    \n    train_dataset = ImageFolder(root=os.path.join(path, 'train'), transform=transform)\n    test_dataset = ImageFolder(root=os.path.join(path, 'test'), transform=transform)\n    \n    print(f\"Image data loaded. Train: {len(train_dataset)} samples, Test: {len(test_dataset)} samples.\")\n    return train_dataset, test_dataset\n    \nfrom tqdm import tqdm # Make sure this is imported\n\ndef load_ved_speech_data(path=os.path.join(BASE_PATH, 'VED (Speech)/Voice Emotion Dataset/'), use_subset=None):\n    \"\"\"\n    Loads VED speech data. If a pre-processed file exists, it loads it.\n    Otherwise, it processes the raw audio, saves the features, and returns them.\n    \"\"\"\n    processed_file = os.path.join(BASE_PATH, 'VED (Speech)/ved_features.pt')\n\n    # If a pre-processed file exists, load it and return instantly.\n    if os.path.exists(processed_file):\n        print(f\"Loading pre-processed VED speech data from {processed_file}...\")\n        data = torch.load(processed_file)\n        print(\"VED speech data loaded instantly.\")\n        return data['features'], data['labels']\n\n    # If not, run the slow one-time processing.\n    print(\"Pre-processed file not found. Starting one-time processing of VED audio files...\")\n    filepaths, labels = [], []\n    label_map = {d: i for i, d in enumerate(os.listdir(path))}\n\n    for emotion_folder, label_idx in label_map.items():\n        folder_path = os.path.join(path, emotion_folder)\n        for filename in os.listdir(folder_path):\n            if filename.endswith(\".wav\"):\n                filepaths.append(os.path.join(folder_path, filename))\n                labels.append(label_idx)\n\n    # If use_subset is set, only process a small number of files for quick testing.\n    if use_subset and isinstance(use_subset, int):\n        print(f\"--- USING SUBSET of {use_subset} files for development ---\")\n        filepaths = filepaths[:use_subset]\n        labels = labels[:use_subset]\n\n    # Feature extraction (MFCCs) with a progress bar.\n    features = []\n    for fp in tqdm(filepaths, desc=\"Processing VED audio files\"):\n        waveform, sr = librosa.load(fp, sr=16000)\n        mfccs = librosa.feature.mfcc(y=waveform, sr=sr, n_mfcc=40)\n        if mfccs.shape[1] < 173:\n            mfccs = np.pad(mfccs, ((0, 0), (0, 173 - mfccs.shape[1])), mode='constant')\n        else:\n            mfccs = mfccs[:, :173]\n        features.append(mfccs)\n\n    features = np.array(features)\n    labels = np.array(labels)\n\n    # Normalize features.\n    scaler = StandardScaler()\n    features = scaler.fit_transform(features.reshape(-1, features.shape[-1])).reshape(features.shape)\n\n    features_tensor = torch.tensor(features, dtype=torch.float32).unsqueeze(1)\n    labels_tensor = torch.tensor(labels, dtype=torch.long)\n\n    # Save the processed data for next time.\n    print(f\"Saving processed features to {processed_file}...\")\n    torch.save({'features': features_tensor, 'labels': labels_tensor}, processed_file)\n    print(\"Save complete.\")\n\n    return features_tensor, labels_tensor\n    \ndef load_deap_eeg_data(path=os.path.join(BASE_PATH, 'DEAP (EEG)/deap-dataset/data_preprocessed_python/')):\n    \"\"\"Loads preprocessed DEAP EEG data.\"\"\"\n    print(\"Loading DEAP EEG data...\")\n    all_data, all_labels_v = [], []\n    for i in range(1, 33): # s01.dat to s32.dat\n        file_path = os.path.join(path, f\"s{str(i).zfill(2)}.dat\")\n        with open(file_path, 'rb') as f:\n            subject_data = pickle.load(f, encoding='latin1')\n        all_data.append(subject_data['data']) # (40 trials, 32 channels, 8064 samples)\n        all_labels_v.append(subject_data['labels'][:, 0]) # Valence labels\n\n    all_data = np.vstack(all_data)\n    all_labels_v = np.hstack(all_labels_v)\n    \n    # DEAP is complex. We'll simplify by taking a segment and binning labels.\n    # Take first ~1 second of data from the 32 EEG channels\n    eeg_features = all_data[:, :32, :128].reshape(all_data.shape[0], -1) \n    \n    # Binarize Valence labels (e.g., low/high)\n    eeg_labels = (all_labels_v > 5).astype(int)\n    \n    scaler = StandardScaler()\n    eeg_features = scaler.fit_transform(eeg_features)\n    \n    print(f\"DEAP EEG data loaded. Found {len(eeg_features)} samples.\")\n    return torch.tensor(eeg_features, dtype=torch.float32), torch.tensor(eeg_labels, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:59.148616Z","iopub.execute_input":"2025-08-09T04:14:59.149714Z","iopub.status.idle":"2025-08-09T04:14:59.164008Z","shell.execute_reply.started":"2025-08-09T04:14:59.149687Z","shell.execute_reply":"2025-08-09T04:14:59.163270Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# --------------------------------------------------------------------------\n## 3. UNIFIED PYTORCH DATASET\n#\n# This class combines all your datasets into one.\n# --------------------------------------------------------------------------\nclass UnifiedMultimodalDataset(Dataset):\n    def __init__(self, split='train'):\n        text_ids, text_masks, text_labels, _ = load_text_data()\n        \n        # This line was corrected in the previous step\n        self.img_train, self.img_test = load_image_data()\n        \n        speech_feat, speech_labels = load_ved_speech_data()\n        eeg_feat, eeg_labels = load_deap_eeg_data()\n        \n        self.text_ids_train, self.text_ids_test, self.text_masks_train, self.text_masks_test, self.text_labels_train, self.text_labels_test = \\\n            train_test_split(text_ids, text_masks, text_labels, test_size=0.2, random_state=42)\n        self.speech_feat_train, self.speech_feat_test, self.speech_labels_train, self.speech_labels_test = \\\n            train_test_split(speech_feat, speech_labels, test_size=0.2, random_state=42)\n        self.eeg_feat_train, self.eeg_feat_test, self.eeg_labels_train, self.eeg_labels_test = \\\n            train_test_split(eeg_feat, eeg_labels, test_size=0.2, random_state=42)\n\n        if split == 'train':\n            # This is the line you need to correct\n            self.image_data = self.img_train\n            self.text_ids, self.text_masks = self.text_ids_train, self.text_masks_train\n            self.speech_feat = self.speech_feat_train\n            self.eeg_feat = self.eeg_feat_train\n        else: # test\n            self.image_data = self.img_test\n            self.text_ids, self.text_masks = self.text_ids_test, self.text_masks_test\n            self.speech_feat = self.speech_feat_test\n            self.eeg_feat = self.eeg_feat_test\n        \n        self.max_len = max(len(self.image_data), len(self.text_ids), len(self.speech_feat), len(self.eeg_feat))\n        print(f\"Created '{split}' dataset with max length {self.max_len}\")\n        \n    def __len__(self):\n        return self.max_len\n\n    def __getitem__(self, idx):\n        # --- Data Alignment Strategy ---\n        # We use the modulo operator (%) to loop over smaller datasets.\n        # This pairs samples randomly but ensures all data is used.\n        \n        try:\n            # Attempt to load the image\n            img, img_label = self.image_data[idx % len(self.image_data)]\n        except Exception as e:\n            # If it fails (e.g., corrupted file), print a warning and load the next sample instead.\n            print(f\"WARNING: Skipping corrupted image at index {idx}. Error: {e}\")\n            # Recursively call __getitem__ for the next index to get a valid sample.\n            return self.__getitem__((idx + 1) % self.max_len)\n\n        text_id = self.text_ids[idx % len(self.text_ids)]\n        text_mask = self.text_masks[idx % len(self.text_ids)]\n        \n        speech = self.speech_feat[idx % len(self.speech_feat)]\n        \n        eeg = self.eeg_feat[idx % len(self.eeg_feat)]\n\n        # We'll use the image label as the primary target for this combined task\n        label = img_label\n        \n        return {\n            \"text_id\": text_id, \"text_mask\": text_mask,\n            \"image\": img, \"speech\": speech, \"eeg\": eeg,\n            \"label\": torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:59.164804Z","iopub.execute_input":"2025-08-09T04:14:59.165058Z","iopub.status.idle":"2025-08-09T04:14:59.530824Z","shell.execute_reply.started":"2025-08-09T04:14:59.165029Z","shell.execute_reply":"2025-08-09T04:14:59.530085Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --------------------------------------------------------------------------\n## 4. MODEL ARCHITECTURE\n#\n# Hybrid Quantum-Classical model components.\n# --------------------------------------------------------------------------\n\n# --- 4.1: Classical Feature Extractors ---\nclass TextFeatureExtractor(nn.Module):\n    def __init__(self, feature_dim=64):\n        super().__init__()\n        self.bert = BertModel.from_pretrained('prajjwal1/bert-tiny')\n        self.fc = nn.Linear(self.bert.config.hidden_size, feature_dim)\n    def forward(self, input_ids, attention_mask):\n        return self.fc(self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output)\n\nclass ImageFeatureExtractor(nn.Module):\n    def __init__(self, feature_dim=64):\n        super().__init__()\n        self.conv = nn.Sequential(nn.Conv2d(3, 16, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n                                  nn.Conv2d(16, 32, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n                                  nn.Flatten())\n        self.fc = nn.Linear(32 * 14 * 14, feature_dim) # Adjusted for 64x64 input\n    def forward(self, x): return self.fc(self.conv(x))\n\nclass SpeechFeatureExtractor(nn.Module):\n    def __init__(self, feature_dim=64):\n        super().__init__()\n        self.conv = nn.Sequential(nn.Conv2d(1, 16, 3), nn.ReLU(), nn.MaxPool2d(2), nn.Flatten())\n        self.fc = nn.Linear(16 * 19 * 85, feature_dim) # Adjusted for MFCC size\n    def forward(self, x): return self.fc(self.conv(x))\n\nclass EEGFeatureExtractor(nn.Module):\n    def __init__(self, feature_dim=64):\n        super().__init__()\n        self.fc = nn.Sequential(nn.Linear(32 * 128, 256), nn.ReLU(), nn.Linear(256, feature_dim))\n    def forward(self, x): return self.fc(x)\n\n# --- 4.2: Attention Fusion ---\nclass AttentionFusion(nn.Module):\n    def __init__(self, feature_dim=64, n_modalities=4):\n        super().__init__()\n        self.attention_fc = nn.Linear(feature_dim, 1)\n    def forward(self, text_f, img_f, speech_f, eeg_f):\n        all_features = torch.stack([text_f, img_f, speech_f, eeg_f], dim=1)\n        att_scores = self.attention_fc(all_features)\n        att_weights = torch.softmax(att_scores, dim=1)\n        fused_vector = torch.sum(all_features * att_weights, dim=1)\n        return fused_vector\n\n# --- 4.3: Quantum Classifier ---|\nn_qubits = 4\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n# =================== NEW SIMPLIFIED QUANTUM COMPONENT ===================\n\n@qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\ndef quantum_circuit(inputs, weights):\n    # Encoding the classical data\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    \n    # A single, simple layer of trainable rotations\n    qml.RX(weights[0], wires=0)\n    qml.RX(weights[1], wires=1)\n    qml.RX(weights[2], wires=2)\n    qml.RX(weights[3], wires=3)\n    \n    # A single, simple layer of entanglement\n    qml.CNOT(wires=[0, 1])\n    qml.CNOT(wires=[1, 2])\n    qml.CNOT(wires=[2, 3])\n    \n    # Return expectation values\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\n\nclass QuantumLayer(nn.Module):\n    def __init__(self, input_dim=128, num_classes=7):\n        super().__init__()\n        self.pre_net = nn.Linear(input_dim, n_qubits)\n        \n        # The new weights shape matches the simpler circuit (4 trainable parameters)\n        weight_shapes = {\"weights\": (n_qubits,)}\n        self.q_layer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n        \n        # The post-net remains the same\n        self.post_net = nn.Linear(n_qubits, num_classes)\n\n    def forward(self, x):\n        # Pre-process the classical features to be suitable as angles\n        x = torch.tanh(self.pre_net(x)) * np.pi / 2.0\n        x = self.q_layer(x)\n        return self.post_net(x)\n\n# ========================================================================\n# --- 4.4: Full Hybrid Model ---\nclass QCC_MultimodalModel(nn.Module):\n    def __init__(self, feature_dim=64, num_classes=7):\n        super().__init__()\n        self.text_extractor = TextFeatureExtractor(feature_dim)\n        self.image_extractor = ImageFeatureExtractor(feature_dim)\n        self.speech_extractor = SpeechFeatureExtractor(feature_dim)\n        self.eeg_extractor = EEGFeatureExtractor(feature_dim)\n        self.fusion = AttentionFusion(feature_dim)\n        # In your QCC_MultimodalModel class\n        self.quantum_classifier = QuantumLayer(feature_dim, num_classes)\n        \n    def forward(self, data):\n        text_f = self.text_extractor(data['text_id'], data['text_mask'])\n        img_f = self.image_extractor(data['image'])\n        speech_f = self.speech_extractor(data['speech'])\n        eeg_f = self.eeg_extractor(data['eeg'])\n        \n        fused = self.fusion(text_f, img_f, speech_f, eeg_f)\n        output = self.quantum_classifier(fused)\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:59.531635Z","iopub.execute_input":"2025-08-09T04:14:59.531928Z","iopub.status.idle":"2025-08-09T04:14:59.553709Z","shell.execute_reply.started":"2025-08-09T04:14:59.531899Z","shell.execute_reply":"2025-08-09T04:14:59.553139Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n#                      STAGE 1: TRAIN AND SAVE CLASSICAL BASELINE\n# ==============================================================================\n\ndef train_and_save_classical_model():\n    \"\"\"\n    Trains the stable classical-only model and saves its weights.\n    \"\"\"\n    # --- Hyperparameters ---\n    EPOCHS = 5\n    BATCH_SIZE = 16\n    LEARNING_RATE = 1e-5\n    FEATURE_DIM = 128\n    NUM_CLASSES = 7\n\n    # --- Define the Classical-Only Model ---\n    # This is the stable architecture from your successful experiment.\n    class ClassicalBaselineModel(nn.Module):\n        def __init__(self, feature_dim=128, num_classes=7):\n            super().__init__()\n            self.text_extractor = TextFeatureExtractor(feature_dim)\n            self.image_extractor = ImageFeatureExtractor(feature_dim)\n            self.speech_extractor = SpeechFeatureExtractor(feature_dim)\n            self.eeg_extractor = EEGFeatureExtractor(feature_dim)\n            self.fusion = AttentionFusion(feature_dim)\n            # Using the stable classical classifier head\n            self.classifier = nn.Sequential(\n                nn.Linear(feature_dim, 64),\n                nn.ReLU(),\n                nn.Linear(64, num_classes)\n            )\n        def forward(self, data):\n            text_f = self.text_extractor(data['text_id'], data['text_mask'])\n            img_f = self.image_extractor(data['image'])\n            speech_f = self.speech_extractor(data['speech'])\n            eeg_f = self.eeg_extractor(data['eeg'])\n            fused = self.fusion(text_f, img_f, speech_f, eeg_f)\n            output = self.classifier(fused)\n            return output\n            \n    # --- Data Loading ---\n    print(\"\\n[PHASE 1] Initializing Datasets...\")\n    train_dataset = UnifiedMultimodalDataset(split='train')\n    test_dataset = UnifiedMultimodalDataset(split='test')\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n    # --- Calculate Class Weights ---\n    print(\"\\nCalculating class weights...\")\n    full_train_labels = [label for _, label in train_dataset.image_data.samples]\n    class_counts = torch.bincount(torch.tensor(full_train_labels)).float()\n    class_weights = 1. / class_counts\n    class_weights = class_weights / class_weights.sum() * NUM_CLASSES\n    class_weights = class_weights.to(DEVICE)\n    print(f\"Calculated Class Weights: {class_weights}\")\n    \n    # --- Model Initialization ---\n    print(\"\\n[PHASE 2] Initializing CLASSICAL BASELINE MODEL...\")\n    model = ClassicalBaselineModel(feature_dim=FEATURE_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # --- Training Loop ---\n    print(\"\\n[PHASE 3] Starting Training...\")\n    for epoch in range(EPOCHS):\n        model.train()\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n        for data in progress_bar:\n            for key in data: data[key] = data[key].to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, data['label'])\n            loss.backward()\n            optimizer.step()\n            progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n\n    # --- Evaluation ---\n    print(\"\\n[PHASE 4] Starting Evaluation...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for data in tqdm(test_loader, desc=\"Evaluating\"):\n            for key in data: data[key] = data[key].to(DEVICE)\n            outputs = model(data)\n            _, predicted = torch.max(outputs.data, 1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(data['label'].cpu().numpy())\n    \n    # --- Save the Model ---\n    print(\"\\nSaving the trained classical baseline model...\")\n    torch.save(model.state_dict(), '/kaggle/working/classical_baseline_model.pth')\n    print(\"âœ… Model saved successfully to /kaggle/working/classical_baseline_model.pth\")\n\n\n# --- Run the Stage 1 script ---\ntrain_and_save_classical_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:14:59.554618Z","iopub.execute_input":"2025-08-09T04:14:59.554868Z","iopub.status.idle":"2025-08-09T04:22:25.985711Z","shell.execute_reply.started":"2025-08-09T04:14:59.554845Z","shell.execute_reply":"2025-08-09T04:22:25.984701Z"}},"outputs":[{"name":"stdout","text":"\n[PHASE 1] Initializing Datasets...\nLoading text data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b6d24f7ca714e1ebb170112aa6fc7f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/285 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfee342e972142e48884428ab39c7bc1"}},"metadata":{}},{"name":"stdout","text":"Text data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'train' dataset with max length 43592\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'test' dataset with max length 10898\n\nCalculating class weights...\nCalculated Class Weights: tensor([0.4800, 4.3982, 0.4681, 0.2658, 0.3862, 0.3970, 0.6047],\n       device='cuda:0')\n\n[PHASE 2] Initializing CLASSICAL BASELINE MODEL...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1adebcfe1654176bf2093f7d8292606"}},"metadata":{}},{"name":"stdout","text":"\n[PHASE 3] Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5:   0%|          | 0/2725 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/17.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03fc2c4a426348f68c7cc2872745b8fa"}},"metadata":{}},{"name":"stderr","text":"Epoch 1/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:29<00:00, 30.29it/s, loss=1.8820]\nEpoch 2/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:51<00:00, 53.39it/s, loss=1.4312]\nEpoch 3/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:51<00:00, 53.31it/s, loss=1.9441]\nEpoch 4/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:51<00:00, 53.32it/s, loss=1.5685]\nEpoch 5/5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:50<00:00, 53.71it/s, loss=1.3790]\n","output_type":"stream"},{"name":"stdout","text":"\n[PHASE 4] Starting Evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682/682 [00:22<00:00, 30.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nSaving the trained classical baseline model...\nâœ… Model saved successfully to /kaggle/working/classical_baseline_model.pth\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# --------------------------------------------------------------------------\n## 5. TRAINING AND EVALUATION\n# --------------------------------------------------------------------------\ndef main():\n    # --- Hyperparameters ---\n    EPOCHS = 10 # We can train for a few more epochs as it will be fast\n    BATCH_SIZE = 16\n    LEARNING_RATE = 1e-5 # Keep the stable learning rate\n    FEATURE_DIM = 128\n    NUM_CLASSES = 7\n    \n    # --- Data Loading ---\n    print(\"\\n[PHASE 1] Initializing Datasets for Fine-Tuning...\")\n    train_dataset = UnifiedMultimodalDataset(split='train')\n    test_dataset = UnifiedMultimodalDataset(split='test')\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n    # --- Model Initialization ---\n    print(\"\\n[PHASE 2] Initializing FULL HYBRID MODEL...\")\n    model = QCC_MultimodalModel(feature_dim=FEATURE_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n    \n    # --- LOAD, FREEZE, and FINE-TUNE ---\n    print(\"\\nLoading weights from the pre-trained classical model...\")\n    # Load the saved weights. strict=False allows us to load a partial model.\n    model.load_state_dict(torch.load('/kaggle/working/classical_baseline_model.pth'), strict=False)\n\n    print(\"Freezing classical layers... â„ï¸\")\n    # Freeze all parameters first\n    for param in model.parameters():\n        param.requires_grad = False\n    # Then, unfreeze ONLY the parameters in the quantum classifier\n    for param in model.quantum_classifier.parameters():\n        param.requires_grad = True\n\n    print(\"\\n--- Trainable Parameters ---\")\n    # Verify that only the quantum layers are trainable\n    for name, param in model.named_parameters():\n        if param.requires_grad:\n            print(f\"âœ… TRAINABLE: {name}\")\n\n    # The optimizer will now only update the unfrozen (quantum) parameters\n    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss() # No need for weights, the features are already well-represented\n    \n    # --- Training Loop (only trains the quantum layer) ---\n    print(\"\\n[PHASE 3] Starting Fine-Tuning of Quantum Layer... ğŸ”¥\")\n    for epoch in range(EPOCHS):\n        model.train()\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n        for i, data in enumerate(progress_bar):\n            for key in data: data[key] = data[key].to(DEVICE)\n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, data['label'])\n            loss.backward()\n            optimizer.step()\n            if (i + 1) % 100 == 0:\n                progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n\n    # --- Evaluation ---\n    print(\"\\n[PHASE 4] Starting Final Evaluation...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for data in tqdm(test_loader, desc=\"Evaluating\"):\n            for key in data: data[key] = data[key].to(DEVICE)\n            outputs = model(data)\n            _, predicted = torch.max(outputs.data, 1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(data['label'].cpu().numpy())\n            \n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    \n    print(\"\\n----------- FINAL QUANTUM MODEL RESULTS -----------\")\n    print(f\"Accuracy on Test Set: {accuracy * 100:.2f}%\")\n    print(f\"Weighted F1-Score on Test Set: {f1:.4f}\")\n    \n    label_names = list(test_dataset.image_data.class_to_idx.keys())\n    print(\"\\n----------- DETAILED CLASSIFICATION REPORT -----------\")\n    print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))\n    \n    print(\"\\n----------- CONFUSION MATRIX -----------\")\n    print(confusion_matrix(all_labels, all_preds))\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:22:25.987144Z","iopub.execute_input":"2025-08-09T04:22:25.987528Z","iopub.status.idle":"2025-08-09T04:36:41.869449Z","shell.execute_reply.started":"2025-08-09T04:22:25.987491Z","shell.execute_reply":"2025-08-09T04:36:41.868715Z"}},"outputs":[{"name":"stdout","text":"\n[PHASE 1] Initializing Datasets for Fine-Tuning...\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'train' dataset with max length 43592\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'test' dataset with max length 10898\n\n[PHASE 2] Initializing FULL HYBRID MODEL...\n\nLoading weights from the pre-trained classical model...\nFreezing classical layers... â„ï¸\n\n--- Trainable Parameters ---\nâœ… TRAINABLE: quantum_classifier.pre_net.weight\nâœ… TRAINABLE: quantum_classifier.pre_net.bias\nâœ… TRAINABLE: quantum_classifier.q_layer.weights\nâœ… TRAINABLE: quantum_classifier.post_net.weight\nâœ… TRAINABLE: quantum_classifier.post_net.bias\n\n[PHASE 3] Starting Fine-Tuning of Quantum Layer... ğŸ”¥\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:18<00:00, 34.86it/s, loss=1.7214]\nEpoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:19<00:00, 34.15it/s, loss=1.8331]\nEpoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:19<00:00, 34.08it/s, loss=1.9989]\nEpoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:18<00:00, 34.69it/s, loss=1.7548]\nEpoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:18<00:00, 34.87it/s, loss=1.7429]\nEpoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:17<00:00, 35.09it/s, loss=1.7479]\nEpoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:18<00:00, 34.82it/s, loss=1.7467]\nEpoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:21<00:00, 33.42it/s, loss=1.6872]\nEpoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:20<00:00, 33.98it/s, loss=1.9332]\nEpoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [01:18<00:00, 34.88it/s, loss=1.6227]\n","output_type":"stream"},{"name":"stdout","text":"\n[PHASE 4] Starting Final Evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682/682 [00:13<00:00, 49.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n----------- FINAL QUANTUM MODEL RESULTS -----------\nAccuracy on Test Set: 36.90%\nWeighted F1-Score on Test Set: 0.2541\n\n----------- DETAILED CLASSIFICATION REPORT -----------\n              precision    recall  f1-score   support\n\n       angry       0.00      0.00      0.00      1916\n     disgust       0.00      0.00      0.00       222\n        fear       0.25      0.62      0.35      2048\n       happy       0.48      0.81      0.60      3401\n     neutral       0.00      0.00      0.00      1233\n         sad       0.00      0.00      0.00      1247\n    surprise       0.00      0.00      0.00       831\n\n    accuracy                           0.37     10898\n   macro avg       0.10      0.20      0.14     10898\nweighted avg       0.20      0.37      0.25     10898\n\n\n----------- CONFUSION MATRIX -----------\n[[   0    0 1086  830    0    0    0]\n [   0    0  139   83    0    0    0]\n [   0    0 1279  769    0    0    0]\n [   0    0  659 2742    0    0    0]\n [   0    0  638  595    0    0    0]\n [   0    0  722  525    0    0    0]\n [   0    0  652  179    0    0    0]]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import Dataset # ADD THIS LINE\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport torch.nn as nn\nimport torch\nimport os\n\n# --- A simpler Dataset for only loading images ---\nclass UnimodalImageDataset(Dataset):\n    def __init__(self, split='train'):\n        # Using the corrected FER-2013 load function\n        self.train_data, self.test_data = load_image_data()\n        self.data = self.train_data if split == 'train' else self.test_data\n    \n    def __len__(self):\n        return len(self.data)\n        \n    def __getitem__(self, idx):\n        # Return only the image and its label\n        image, label = self.data[idx]\n        return image, label\n\n# --- A simpler Model for the unimodal task ---\nclass UnimodalQuantumModel(nn.Module):\n    def __init__(self, feature_dim=128, num_classes=7):\n        super().__init__()\n        self.image_extractor = ImageFeatureExtractor(feature_dim)\n        # Using the same simplified quantum layer\n        self.quantum_classifier = QuantumLayer(feature_dim, num_classes)\n\n    def forward(self, image):\n        # The data path is much simpler now\n        img_features = self.image_extractor(image)\n        output = self.quantum_classifier(img_features)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:36:41.872336Z","iopub.execute_input":"2025-08-09T04:36:41.872584Z","iopub.status.idle":"2025-08-09T04:36:41.879270Z","shell.execute_reply.started":"2025-08-09T04:36:41.872564Z","shell.execute_reply":"2025-08-09T04:36:41.878715Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\n\n# Ensure all other necessary classes like UnimodalImageDataset and \n# UnimodalQuantumModel are defined in cells before this one.\n\ndef train_unimodal_model():\n    \"\"\"\n    Trains and evaluates the unimodal (image-only) quantum model.\n    \"\"\"\n    print(\"\\n--- Starting Unimodal (Image-Only) Quantum Model Training ---\")\n    \n    # --- Hyperparameters ---\n    EPOCHS = 15 \n    BATCH_SIZE = 32\n    LEARNING_RATE = 1e-5\n    FEATURE_DIM = 128\n    NUM_CLASSES = 7\n    \n    # --- Data Loading ---\n    uni_train_dataset = UnimodalImageDataset(split='train')\n    uni_test_dataset = UnimodalImageDataset(split='test')\n    uni_train_loader = DataLoader(uni_train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    uni_test_loader = DataLoader(uni_test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n    \n    # --- Model Initialization ---\n    uni_model = UnimodalQuantumModel(feature_dim=FEATURE_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n    optimizer = optim.Adam(uni_model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss()\n    \n    # --- Training Loop ---\n    for epoch in range(EPOCHS):\n        uni_model.train()\n        progress_bar = tqdm(uni_train_loader, desc=f\"Unimodal Epoch {epoch+1}/{EPOCHS}\")\n        for images, labels in progress_bar:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = uni_model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n            \n    # --- Evaluation ---\n    uni_model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in tqdm(uni_test_loader, desc=\"Evaluating Unimodal Model\"):\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = uni_model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n    print(\"\\n----------- UNIMODAL QUANTUM MODEL RESULTS -----------\")\n    label_names = list(uni_train_dataset.data.class_to_idx.keys())\n    print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))\n    \n    # Return the trained model and the dataloader for the next step\n    return uni_model, uni_train_loader\n\ndef plot_loss_landscape(model, dataloader, device):\n    \"\"\"\n    Plots the loss landscape with respect to the first trainable quantum parameter.\n    \"\"\"\n    print(\"\\n--- Analyzing Loss Landscape ---\")\n    \n    # Isolate the first trainable parameter in the quantum layer\n    target_param = model.quantum_classifier.q_layer.weights\n    \n    # Get its final trained value\n    original_value = target_param.data[0].item()\n    print(f\"Analyzing first parameter. Final trained value: {original_value:.4f}\")\n\n    # Create a range of values around the final value\n    param_range = np.linspace(original_value - 2*np.pi, original_value + 2*np.pi, 25)\n    losses = []\n\n    # Get a single batch of data to test with\n    images, labels = next(iter(dataloader))\n    images, labels = images.to(device), labels.to(device)\n    criterion = nn.CrossEntropyLoss()\n\n    # Calculate loss for each parameter value\n    for val in tqdm(param_range, desc=\"Scanning Landscape\"):\n        # Manually set the parameter's value\n        target_param.data[0] = float(val)\n        \n        with torch.no_grad():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            losses.append(loss.item())\n\n    # Reset the parameter to its original value\n    target_param.data[0] = original_value\n\n    # Plot the results\n    plt.figure(figsize=(10, 6))\n    plt.plot(param_range, losses, marker='o', linestyle='-')\n    plt.axvline(x=original_value, color='r', linestyle='--', label=f'Final Trained Value ({original_value:.2f})')\n    plt.xlabel(\"Parameter Value (Radians)\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss Landscape of a Single Quantum Parameter\")\n    # ... (rest of the plotting setup code)\n    plt.legend()\n    plt.grid(True)\n\n    # --- CORRECT ORDER ---\n    # 1. Save the figure to a file first.\n    # The bbox_inches='tight' argument helps ensure nothing is cut off.\n    plt.savefig(\"loss_landscape.png\", dpi=300, bbox_inches='tight')\n    \n    # 2. Then, display the plot on the screen.\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:36:41.879934Z","iopub.execute_input":"2025-08-09T04:36:41.880180Z","iopub.status.idle":"2025-08-09T04:36:41.904130Z","shell.execute_reply.started":"2025-08-09T04:36:41.880163Z","shell.execute_reply":"2025-08-09T04:36:41.903572Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# --- Run the Unimodal Experiment and Capture the Output ---\ntrained_unimodal_model, train_loader_for_plot = train_unimodal_model()\n\n# --- Run the Loss Landscape Analysis on the Captured Model ---\n# This will now work because 'trained_unimodal_model' exists\nplot_loss_landscape(trained_unimodal_model, train_loader_for_plot, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:36:41.904843Z","iopub.execute_input":"2025-08-09T04:36:41.905064Z","iopub.status.idle":"2025-08-09T04:43:28.213703Z","shell.execute_reply.started":"2025-08-09T04:36:41.905039Z","shell.execute_reply":"2025-08-09T04:43:28.212809Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Unimodal (Image-Only) Quantum Model Training ---\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\n","output_type":"stream"},{"name":"stderr","text":"Unimodal Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 34.48it/s, loss=1.9040]\nUnimodal Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.19it/s, loss=1.7671]\nUnimodal Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 34.62it/s, loss=2.0534]\nUnimodal Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.08it/s, loss=1.7422]\nUnimodal Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.49it/s, loss=1.8600]\nUnimodal Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.17it/s, loss=1.7232]\nUnimodal Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.63it/s, loss=1.8369]\nUnimodal Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 33.82it/s, loss=1.8484]\nUnimodal Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 34.23it/s, loss=2.0122]\nUnimodal Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:25<00:00, 35.25it/s, loss=1.7270]\nUnimodal Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 33.71it/s, loss=1.8281]\nUnimodal Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 33.94it/s, loss=1.7641]\nUnimodal Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 34.30it/s, loss=1.7608]\nUnimodal Epoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 34.10it/s, loss=1.8066]\nUnimodal Epoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 898/898 [00:26<00:00, 34.09it/s, loss=1.8842]\nEvaluating Unimodal Model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225/225 [00:05<00:00, 39.32it/s]","output_type":"stream"},{"name":"stdout","text":"\n----------- UNIMODAL QUANTUM MODEL RESULTS -----------\n              precision    recall  f1-score   support\n\n       angry       0.00      0.00      0.00       958\n     disgust       0.00      0.00      0.00       111\n        fear       0.00      0.00      0.00      1024\n       happy       0.34      0.82      0.48      1774\n     neutral       0.00      0.00      0.00      1233\n         sad       0.17      0.40      0.24      1247\n    surprise       0.00      0.00      0.00       831\n\n    accuracy                           0.27      7178\n   macro avg       0.07      0.18      0.10      7178\nweighted avg       0.11      0.27      0.16      7178\n\n\n--- Analyzing Loss Landscape ---\nAnalyzing first parameter. Final trained value: 5.9786\n","output_type":"stream"},{"name":"stderr","text":"\nScanning Landscape: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:00<00:00, 109.54it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"!pip uninstall qiskit qiskit-aer qiskit-machine-learning -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:43:28.214676Z","iopub.execute_input":"2025-08-09T04:43:28.214887Z","iopub.status.idle":"2025-08-09T04:43:30.328356Z","shell.execute_reply.started":"2025-08-09T04:43:28.214867Z","shell.execute_reply":"2025-08-09T04:43:30.327499Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping qiskit as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping qiskit-aer as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping qiskit-machine-learning as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install qiskit==1.1.1 qiskit-aer==0.14.2 qiskit-machine-learning==0.8.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:43:30.329587Z","iopub.execute_input":"2025-08-09T04:43:30.329926Z","iopub.status.idle":"2025-08-09T04:43:53.379508Z","shell.execute_reply.started":"2025-08-09T04:43:30.329894Z","shell.execute_reply":"2025-08-09T04:43:53.378706Z"}},"outputs":[{"name":"stdout","text":"Collecting qiskit==1.1.1\n  Downloading qiskit-1.1.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\nCollecting qiskit-aer==0.14.2\n  Downloading qiskit_aer-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\nCollecting qiskit-machine-learning==0.8.0\n  Downloading qiskit_machine_learning-0.8.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (0.16.0)\nRequirement already satisfied: numpy<3,>=1.17 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (1.26.4)\nRequirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (1.15.3)\nRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (1.13.1)\nRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (0.3.8)\nRequirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (2.9.0.post0)\nCollecting stevedore>=3.0.0 (from qiskit==1.1.1)\n  Downloading stevedore-5.4.1-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from qiskit==1.1.1) (4.14.0)\nCollecting symengine>=0.11 (from qiskit==1.1.1)\n  Downloading symengine-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: psutil>=5 in /usr/local/lib/python3.11/dist-packages (from qiskit-aer==0.14.2) (7.0.0)\nRequirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning==0.8.0) (1.2.2)\nCollecting fastdtw (from qiskit-machine-learning==0.8.0)\n  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: setuptools>=40.1.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-machine-learning==0.8.0) (75.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.17->qiskit==1.1.1) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit==1.1.1) (1.17.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning==0.8.0) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->qiskit-machine-learning==0.8.0) (3.6.0)\nCollecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit==1.1.1)\n  Downloading pbr-6.1.1-py2.py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit==1.1.1) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.17->qiskit==1.1.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.17->qiskit==1.1.1) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.17->qiskit==1.1.1) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.17->qiskit==1.1.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.17->qiskit==1.1.1) (2024.2.0)\nDownloading qiskit-1.1.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hDownloading qiskit_aer-0.14.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading qiskit_machine_learning-0.8.0-py3-none-any.whl (237 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading stevedore-5.4.1-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading symengine-0.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pbr-6.1.1-py2.py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fastdtw\n  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp311-cp311-linux_x86_64.whl size=542078 sha256=f0464a58bbbd55d3f3b54032ef2ceec96caca47bdf6c531e3b4b0db845e6fe2b\n  Stored in directory: /root/.cache/pip/wheels/5c/8a/f6/fd3df9a9714677410a5ccbf3ca519e66db4a54a1c46ea95332\nSuccessfully built fastdtw\nInstalling collected packages: symengine, pbr, stevedore, qiskit, fastdtw, qiskit-machine-learning, qiskit-aer\nSuccessfully installed fastdtw-0.3.4 pbr-6.1.1 qiskit-1.1.1 qiskit-aer-0.14.2 qiskit-machine-learning-0.8.0 stevedore-5.4.1 symengine-0.14.1\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# --- Install/Import necessary libraries ---\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.svm import SVC\nfrom sklearn.utils import shuffle # ADD THIS IMPORT\nfrom qiskit_aer.primitives import Sampler\nfrom qiskit.circuit.library import ZZFeatureMap\nfrom qiskit_machine_learning.kernels import FidelityQuantumKernel\n\nprint(\"\\n--- Starting Comparative Study: Quantum Support Vector Machine (QSVM) ---\")\n\n# --- 1. Prepare the Data (same as before) ---\nprint(\"Re-initializing the dataset for the QSVM experiment...\")\nuni_train_dataset = UnimodalImageDataset(split='train')\nuni_model = trained_unimodal_model \n\nX_train = []\ny_train = []\nfor img, label in tqdm(uni_train_dataset, desc=\"Extracting training features\"):\n    with torch.no_grad():\n        features = uni_model.image_extractor(img.unsqueeze(0).to(DEVICE))\n    X_train.append(features.cpu().numpy().flatten())\n    y_train.append(label)\n\nX_train = np.array(X_train)\ny_train = np.array(y_train)\n\nn_features = 4\npca = PCA(n_components=n_features)\nX_train_pca = pca.fit_transform(X_train)\nscaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train_pca)\n\n# --- THE FIX IS HERE ---\n# Shuffle the data before taking a subset\nprint(\"\\nShuffling data...\")\nX_train_shuffled, y_train_shuffled = shuffle(X_train_scaled, y_train, random_state=42)\n\n# --- 2. Define the Quantum Kernel (same as before) ---\nfeature_map = ZZFeatureMap(feature_dimension=n_features, reps=2, entanglement='linear')\nquantum_kernel = FidelityQuantumKernel(feature_map=feature_map)\nsvc = SVC(kernel=quantum_kernel.evaluate)\n\n# --- 3. Train the SVC with the SHUFFLED Quantum Kernel data ---\nprint(\"\\nTraining SVC with Quantum Kernel... (This may take some time)\")\nsubset_size = 500\nsvc.fit(X_train_shuffled[:subset_size], y_train_shuffled[:subset_size])\n\n# --- 4. Evaluate ---\nprint(\"\\nEvaluating...\")\n# Evaluate on the same subset for consistency\nqsvc_score = svc.score(X_train_shuffled[:subset_size], y_train_shuffled[:subset_size])\n\nprint(\"\\n----------- SVC with QUANTUM KERNEL RESULTS -----------\")\nprint(f\"Accuracy on Training Subset: {qsvc_score * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T04:43:53.380718Z","iopub.execute_input":"2025-08-09T04:43:53.381029Z","iopub.status.idle":"2025-08-09T05:01:45.676770Z","shell.execute_reply.started":"2025-08-09T04:43:53.380993Z","shell.execute_reply":"2025-08-09T05:01:45.675885Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Comparative Study: Quantum Support Vector Machine (QSVM) ---\nRe-initializing the dataset for the QSVM experiment...\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\n","output_type":"stream"},{"name":"stderr","text":"Extracting training features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28709/28709 [00:48<00:00, 590.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nShuffling data...\n\nTraining SVC with Quantum Kernel... (This may take some time)\n\nEvaluating...\n\n----------- SVC with QUANTUM KERNEL RESULTS -----------\nAccuracy on Training Subset: 41.60%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class AblationClassicalModel(nn.Module):\n    def __init__(self, feature_dim=128, num_classes=7, use_text=True, use_image=True, use_speech=True, use_eeg=True):\n        super().__init__()\n        self.feature_dim = feature_dim\n        # Store which modalities to use\n        self.use_text = use_text\n        self.use_image = use_image\n        self.use_speech = use_speech\n        self.use_eeg = use_eeg\n\n        # Define extractors\n        self.text_extractor = TextFeatureExtractor(feature_dim)\n        self.image_extractor = ImageFeatureExtractor(feature_dim)\n        self.speech_extractor = SpeechFeatureExtractor(feature_dim)\n        self.eeg_extractor = EEGFeatureExtractor(feature_dim)\n\n        self.fusion = AttentionFusion(feature_dim)\n\n        # Using the stable classical classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(feature_dim, 64),\n            nn.ReLU(),\n            nn.Linear(64, num_classes)\n        )\n\n    def forward(self, data):\n        # If a modality is not used, create a zero-tensor as a placeholder\n        text_f = self.text_extractor(data['text_id'], data['text_mask']) if self.use_text else torch.zeros(data['image'].size(0), self.feature_dim, device=data['image'].device)\n        img_f = self.image_extractor(data['image']) if self.use_image else torch.zeros(data['image'].size(0), self.feature_dim, device=data['image'].device)\n        speech_f = self.speech_extractor(data['speech']) if self.use_speech else torch.zeros(data['image'].size(0), self.feature_dim, device=data['image'].device)\n        eeg_f = self.eeg_extractor(data['eeg']) if self.use_eeg else torch.zeros(data['image'].size(0), self.feature_dim, device=data['image'].device)\n\n        fused = self.fusion(text_f, img_f, speech_f, eeg_f)\n        output = self.classifier(fused)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:01:45.677754Z","iopub.execute_input":"2025-08-09T05:01:45.678896Z","iopub.status.idle":"2025-08-09T05:01:45.686177Z","shell.execute_reply.started":"2025-08-09T05:01:45.678873Z","shell.execute_reply":"2025-08-09T05:01:45.685444Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def run_ablation_studies():\n    print(\"\\n--- Starting Ablation Studies ---\")\n    \n    # --- Common Hyperparameters ---\n    EPOCHS = 5 \n    BATCH_SIZE = 32\n    LEARNING_RATE = 1e-5\n    FEATURE_DIM = 128\n    NUM_CLASSES = 7\n    \n    # --- Data Loading (done once) ---\n    train_dataset = UnifiedMultimodalDataset(split='train')\n    test_dataset = UnifiedMultimodalDataset(split='test')\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n    \n    # --- Experiments to Run ---\n    experiments = {\n        \"Text+Image\": {\"use_text\": True, \"use_image\": True, \"use_speech\": False, \"use_eeg\": False},\n        \"Speech+EEG\": {\"use_text\": False, \"use_image\": False, \"use_speech\": True, \"use_eeg\": True},\n        \"Image+Speech\": {\"use_text\": False, \"use_image\": True, \"use_speech\": True, \"use_eeg\": False},\n        \"All_Modalities\": {\"use_text\": True, \"use_image\": True, \"use_speech\": True, \"use_eeg\": True}\n    }\n    \n    results = {}\n\n    for name, config in experiments.items():\n        print(f\"\\n--- Running Experiment: {name} ---\")\n        \n        model = AblationClassicalModel(feature_dim=FEATURE_DIM, num_classes=NUM_CLASSES, **config).to(DEVICE)\n        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n        criterion = nn.CrossEntropyLoss()\n        \n        # Training Loop\n        for epoch in range(EPOCHS):\n            model.train()\n            progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} ({name})\")\n            for data in progress_bar:\n                for key in data: data[key] = data[key].to(DEVICE)\n                optimizer.zero_grad()\n                outputs = model(data)\n                loss = criterion(outputs, data['label'])\n                loss.backward()\n                optimizer.step()\n                progress_bar.set_postfix(loss=f'{loss.item():.4f}')\n        \n        # Evaluation\n        model.eval()\n        all_preds, all_labels = [], []\n        with torch.no_grad():\n            for data in tqdm(test_loader, desc=f\"Evaluating {name}\"):\n                for key in data: data[key] = data[key].to(DEVICE)\n                outputs = model(data)\n                _, predicted = torch.max(outputs.data, 1)\n                all_preds.extend(predicted.cpu().numpy())\n                all_labels.extend(data['label'].cpu().numpy())\n        \n        # --- THE FIX IS HERE ---\n        # The accuracy score is now correctly calculated between the true labels and the predictions.\n        accuracy = accuracy_score(all_labels, all_preds)\n        f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n        results[name] = {\"Accuracy\": accuracy, \"F1-Score\": f1}\n\n    print(\"\\n\\n--- ABLATION STUDY FINAL RESULTS ---\")\n    for name, metrics in results.items():\n        print(f\"Configuration: {name}\")\n        print(f\"  Accuracy: {metrics['Accuracy']*100:.2f}%\")\n        print(f\"  F1-Score: {metrics['F1-Score']:.4f}\")\n        print(\"-\" * 20)\n        \n# --- Run the study ---\nrun_ablation_studies()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:01:45.686965Z","iopub.execute_input":"2025-08-09T05:01:45.687314Z","iopub.status.idle":"2025-08-09T05:15:49.796015Z","shell.execute_reply.started":"2025-08-09T05:01:45.687290Z","shell.execute_reply":"2025-08-09T05:15:49.795264Z"}},"outputs":[{"name":"stdout","text":"\n--- Starting Ablation Studies ---\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'train' dataset with max length 43592\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'test' dataset with max length 10898\n\n--- Running Experiment: Text+Image ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5 (Text+Image): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.75it/s, loss=1.3959]\nEpoch 2/5 (Text+Image): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.18it/s, loss=1.7088]\nEpoch 3/5 (Text+Image): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.22it/s, loss=1.7431]\nEpoch 4/5 (Text+Image): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.24it/s, loss=1.4503]\nEpoch 5/5 (Text+Image): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.05it/s, loss=1.8413]\nEvaluating Text+Image: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 341/341 [00:09<00:00, 36.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Running Experiment: Speech+EEG ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5 (Speech+EEG): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.09it/s, loss=1.5340]\nEpoch 2/5 (Speech+EEG): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:35<00:00, 38.07it/s, loss=1.7326]\nEpoch 3/5 (Speech+EEG): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.50it/s, loss=1.3722]\nEpoch 4/5 (Speech+EEG): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.30it/s, loss=1.8055]\nEpoch 5/5 (Speech+EEG): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.38it/s, loss=1.6694]\nEvaluating Speech+EEG: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 341/341 [00:09<00:00, 36.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Running Experiment: Image+Speech ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5 (Image+Speech): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.37it/s, loss=1.6349]\nEpoch 2/5 (Image+Speech): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:36<00:00, 37.08it/s, loss=1.4644]\nEpoch 3/5 (Image+Speech): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.68it/s, loss=1.5181]\nEpoch 4/5 (Image+Speech): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.15it/s, loss=1.2712]\nEpoch 5/5 (Image+Speech): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:38<00:00, 35.58it/s, loss=1.5567]\nEvaluating Image+Speech: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 341/341 [00:09<00:00, 35.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n--- Running Experiment: All_Modalities ---\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5 (All_Modalities): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.03it/s, loss=1.7448]\nEpoch 2/5 (All_Modalities): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:37<00:00, 36.16it/s, loss=1.1926]\nEpoch 3/5 (All_Modalities): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:41<00:00, 33.18it/s, loss=1.5653]\nEpoch 4/5 (All_Modalities): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:40<00:00, 33.94it/s, loss=1.7171]\nEpoch 5/5 (All_Modalities): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1363/1363 [00:40<00:00, 33.53it/s, loss=1.4788]\nEvaluating All_Modalities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 341/341 [00:10<00:00, 33.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n\n--- ABLATION STUDY FINAL RESULTS ---\nConfiguration: Text+Image\n  Accuracy: 40.98%\n  F1-Score: 0.3654\n--------------------\nConfiguration: Speech+EEG\n  Accuracy: 31.21%\n  F1-Score: 0.1497\n--------------------\nConfiguration: Image+Speech\n  Accuracy: 41.81%\n  F1-Score: 0.3757\n--------------------\nConfiguration: All_Modalities\n  Accuracy: 41.38%\n  F1-Score: 0.3683\n--------------------\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class HybridFusionModel(nn.Module):\n    def __init__(self, feature_dim=128, num_classes=7):\n        super().__init__()\n        self.feature_dim = feature_dim\n\n        # --- 1. Unimodal Feature Extractors (Same as before) ---\n        self.text_extractor = TextFeatureExtractor(feature_dim)\n        self.image_extractor = ImageFeatureExtractor(feature_dim)\n        self.speech_extractor = SpeechFeatureExtractor(feature_dim)\n        self.eeg_extractor = EEGFeatureExtractor(feature_dim)\n        \n        # --- 2. NEW: Paired \"Mini-Fusion\" Layers ---\n        # Layer to learn Audio-Visual (Image+Speech) interactions\n        self.audiovisual_fusion = nn.Sequential(\n            nn.Linear(feature_dim * 2, feature_dim),\n            nn.ReLU(),\n        )\n        # Layer to learn Linguistic-Acoustic (Text+Speech) interactions\n        self.textual_acoustic_fusion = nn.Sequential(\n            nn.Linear(feature_dim * 2, feature_dim),\n            nn.ReLU(),\n        )\n\n        # --- 3. Final Global Classifier ---\n        # This now takes all original features + the new paired features as input\n        # Total input size = 4 (unimodal) + 2 (paired) = 6 * feature_dim\n        self.final_classifier = nn.Sequential(\n            nn.Linear(feature_dim * 6, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, data):\n        # --- Get Unimodal Features ---\n        text_f = self.text_extractor(data['text_id'], data['text_mask'])\n        img_f = self.image_extractor(data['image'])\n        speech_f = self.speech_extractor(data['speech'])\n        eeg_f = self.eeg_extractor(data['eeg'])\n        \n        # --- Create Paired Features ---\n        # Combine image and speech features\n        audiovisual_input = torch.cat([img_f, speech_f], dim=1)\n        audiovisual_f = self.audiovisual_fusion(audiovisual_input)\n        \n        # Combine text and speech features\n        textual_acoustic_input = torch.cat([text_f, speech_f], dim=1)\n        textual_acoustic_f = self.textual_acoustic_fusion(textual_acoustic_input)\n        \n        # --- Final Global Fusion (Concatenation) ---\n        # Combine all available features into one large vector\n        global_fused_vector = torch.cat([\n            text_f, \n            img_f, \n            speech_f, \n            eeg_f, \n            audiovisual_f, \n            textual_acoustic_f\n        ], dim=1)\n        \n        # --- Get Final Prediction ---\n        output = self.final_classifier(global_fused_vector)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:15:49.797310Z","iopub.execute_input":"2025-08-09T05:15:49.797559Z","iopub.status.idle":"2025-08-09T05:15:49.805403Z","shell.execute_reply.started":"2025-08-09T05:15:49.797538Z","shell.execute_reply":"2025-08-09T05:15:49.804786Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def main():\n    # --- Hyperparameters ---\n    EPOCHS = 15\n    BATCH_SIZE = 16\n    LEARNING_RATE = 1e-5\n    FEATURE_DIM = 128\n    NUM_CLASSES = 7\n    \n    # --- Data Loading ---\n    print(\"\\n[PHASE 1] Initializing Datasets...\")\n    train_dataset = UnifiedMultimodalDataset(split='train')\n    test_dataset = UnifiedMultimodalDataset(split='test')\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n    # --- Calculate Class Weights to Handle Imbalance ---\n    print(\"\\nCalculating class weights...\")\n    full_train_labels = [label for _, label in train_dataset.image_data.samples]\n    class_counts = torch.bincount(torch.tensor(full_train_labels)).float()\n    class_weights = 1. / class_counts\n    class_weights = class_weights / class_weights.sum() * NUM_CLASSES\n    class_weights = class_weights.to(DEVICE)\n    print(f\"Calculated Class Weights: {class_weights}\")\n    \n    # --- Model Initialization ---\n    print(\"\\n[PHASE 2] Initializing HYBRID FUSION MODEL...\")\n    model = HybridFusionModel(feature_dim=FEATURE_DIM, num_classes=NUM_CLASSES).to(DEVICE)\n    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n    criterion = nn.CrossEntropyLoss(weight=class_weights)\n    \n    # --- Training Loop ---\n    print(\"\\n[PHASE 3] Starting Training...\")\n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n        for i, data in enumerate(progress_bar):\n            # Move data to device\n            for key in data:\n                data[key] = data[key].to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(data)\n            loss = criterion(outputs, data['label'])\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            if (i + 1) % 100 == 0: # Print progress every 100 steps\n                progress_bar.set_postfix(loss=f'{(running_loss / 100):.4f}')\n                running_loss = 0.0\n\n    # --- Evaluation ---\n    print(\"\\n[PHASE 4] Starting Evaluation...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for data in tqdm(test_loader, desc=\"Evaluating\"):\n            for key in data:\n                data[key] = data[key].to(DEVICE)\n            \n            outputs = model(data)\n            _, predicted = torch.max(outputs.data, 1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(data['label'].cpu().numpy())\n            \n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n    \n    print(\"\\n----------- HYBRID FUSION MODEL RESULTS -----------\")\n    print(f\"Accuracy on Test Set: {accuracy * 100:.2f}%\")\n    print(f\"Weighted F1-Score on Test Set: {f1:.4f}\")\n    print(\"------------------------------------------\")\n    \n    label_names = list(test_dataset.image_data.class_to_idx.keys())\n    print(\"\\n----------- DETAILED CLASSIFICATION REPORT -----------\")\n    print(classification_report(all_labels, all_preds, target_names=label_names, zero_division=0))\n    \n    print(\"\\n----------- CONFUSION MATRIX -----------\")\n    conf_matrix = confusion_matrix(all_labels, all_preds)\n    print(conf_matrix)\n\n# --- Run the experiment ---\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:15:49.806117Z","iopub.execute_input":"2025-08-09T05:15:49.806355Z","iopub.status.idle":"2025-08-09T05:28:48.007578Z","shell.execute_reply.started":"2025-08-09T05:15:49.806330Z","shell.execute_reply":"2025-08-09T05:28:48.006734Z"}},"outputs":[{"name":"stdout","text":"\n[PHASE 1] Initializing Datasets...\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'train' dataset with max length 43592\nLoading text data...\nText data loaded. Found 34792 samples.\nLoading image data from FER-2013 dataset...\nImage data loaded. Train: 28709 samples, Test: 7178 samples.\nLoading pre-processed VED speech data from /kaggle/input/multimodel-emotion-data/multimodal-emotion-data/VED (Speech)/ved_features.pt...\nVED speech data loaded instantly.\nLoading DEAP EEG data...\nDEAP EEG data loaded. Found 1280 samples.\nCreated 'test' dataset with max length 10898\n\nCalculating class weights...\nCalculated Class Weights: tensor([0.4800, 4.3982, 0.4681, 0.2658, 0.3862, 0.3970, 0.6047],\n       device='cuda:0')\n\n[PHASE 2] Initializing HYBRID FUSION MODEL...\n\n[PHASE 3] Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:47<00:00, 57.85it/s, loss=1.8694]\nEpoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:47<00:00, 57.64it/s, loss=1.7371]\nEpoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 59.20it/s, loss=1.7072]\nEpoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 58.28it/s, loss=1.6920]\nEpoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 59.04it/s, loss=1.6387]\nEpoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:47<00:00, 57.63it/s, loss=1.5888]\nEpoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 58.77it/s, loss=1.5527]\nEpoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 58.73it/s, loss=1.5287]\nEpoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:46<00:00, 58.65it/s, loss=1.4730]\nEpoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:48<00:00, 56.61it/s, loss=1.4656]\nEpoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:48<00:00, 56.69it/s, loss=1.3906]\nEpoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:47<00:00, 57.47it/s, loss=1.3784]\nEpoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:54<00:00, 50.17it/s, loss=1.2735]\nEpoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:51<00:00, 52.92it/s, loss=1.2797]\nEpoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2725/2725 [00:48<00:00, 56.57it/s, loss=1.2276]\n","output_type":"stream"},{"name":"stdout","text":"\n[PHASE 4] Starting Evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 682/682 [00:13<00:00, 51.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n----------- HYBRID FUSION MODEL RESULTS -----------\nAccuracy on Test Set: 41.11%\nWeighted F1-Score on Test Set: 0.4127\n------------------------------------------\n\n----------- DETAILED CLASSIFICATION REPORT -----------\n              precision    recall  f1-score   support\n\n       angry       0.31      0.37      0.34      1916\n     disgust       0.12      0.45      0.19       222\n        fear       0.31      0.32      0.32      2048\n       happy       0.69      0.60      0.64      3401\n     neutral       0.35      0.23      0.28      1233\n         sad       0.27      0.14      0.19      1247\n    surprise       0.40      0.60      0.48       831\n\n    accuracy                           0.41     10898\n   macro avg       0.35      0.39      0.35     10898\nweighted avg       0.43      0.41      0.41     10898\n\n\n----------- CONFUSION MATRIX -----------\n[[ 705  167  410  263  136  113  122]\n [  59   99   22   17   12    7    6]\n [ 398  142  665  255  130  139  319]\n [ 440  160  419 2056  106  104  116]\n [ 273   98  230  172  283   80   97]\n [ 313  110  277  181  112  175   79]\n [  61   33  146   50   24   20  497]]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def plot_loss_landscape(model, dataloader, device):\n    # ... (all the existing code for the plotting function) ...\n\n    # Plot the results\n    plt.figure(figsize=(10, 6))\n    plt.plot(param_range, losses, marker='o', linestyle='-')\n    plt.axvline(x=original_value, color='r', linestyle='--', label=f'Final Trained Value ({original_value:.2f})')\n    plt.xlabel(\"Parameter Value (Radians)\")\n    plt.ylabel(\"Loss\")\n    plt.title(\"Loss Landscape of a Single Quantum Parameter\")\n    plt.legend()\n    plt.grid(True)\n    \n    # --- CHANGE IS HERE ---\n    # Replace plt.show() with this line to save the file\n    plt.savefig(\"loss_landscape.png\", dpi=300) # dpi=300 for high quality\n    \n    # After running this, a file named 'loss_landscape.png' will be saved in your Kaggle output directory.\n    # You will need to download this file to your computer.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:28:48.008819Z","iopub.execute_input":"2025-08-09T05:28:48.009065Z","iopub.status.idle":"2025-08-09T05:28:48.014419Z","shell.execute_reply.started":"2025-08-09T05:28:48.009043Z","shell.execute_reply":"2025-08-09T05:28:48.013706Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import os\n\nprint(\"Files in the output directory:\")\nprint(os.listdir('/kaggle/working/'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:28:48.015169Z","iopub.execute_input":"2025-08-09T05:28:48.015724Z","iopub.status.idle":"2025-08-09T05:28:48.037049Z","shell.execute_reply.started":"2025-08-09T05:28:48.015705Z","shell.execute_reply":"2025-08-09T05:28:48.036369Z"}},"outputs":[{"name":"stdout","text":"Files in the output directory:\n['classical_baseline_model.pth', '.virtual_documents', 'loss_landscape.png']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# This function assumes you have the final confusion matrix stored in a variable\n# named 'conf_matrix' and the class labels in 'label_names'.\n\ndef plot_visualized_confusion_matrix(cm, class_names):\n    \"\"\"\n    Renders a professional-looking confusion matrix as a heatmap.\n    \"\"\"\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix for Hybrid Fusion Model')\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.savefig(\"confusion_matrix.png\", dpi=300, bbox_inches='tight')\n    plt.show()\n\n# --- How to use it ---\n# After your final evaluation, call the function:\n# plot_visualized_confusion_matrix(conf_matrix, label_names)\n\n# NOTE: Generating the Training/Validation curves requires modifying the\n# training loop to save the loss/accuracy after each epoch for both\n# training and validation sets, and then plotting them.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:29:57.313903Z","iopub.execute_input":"2025-08-09T05:29:57.314685Z","iopub.status.idle":"2025-08-09T05:29:57.560475Z","shell.execute_reply.started":"2025-08-09T05:29:57.314655Z","shell.execute_reply":"2025-08-09T05:29:57.559702Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T05:30:15.204320Z","iopub.execute_input":"2025-08-09T05:30:15.205349Z","iopub.status.idle":"2025-08-09T05:30:15.453064Z","shell.execute_reply.started":"2025-08-09T05:30:15.205323Z","shell.execute_reply":"2025-08-09T05:30:15.452161Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1397662459.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_visualized_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'conf_matrix' is not defined"],"ename":"NameError","evalue":"name 'conf_matrix' is not defined","output_type":"error"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}